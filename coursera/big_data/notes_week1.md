# Week1
## Purpose:
Gather, store and manipulate data to get insight.
## How much data is there and can we manage it?

90% of the wolds data has been created in the last two years.
2020: 35ZB, 40 trillion Gigabytes

Data growth is growing and being driven by **unstructured data** 88% of the data.

Gigabyte -> x 1024 Terabyte -> x1024 Petabyte ->x1024 Exabyte -> 1024 Zetabyte

#The Emerging Big Data Stack
##Functional Requirements
1. collection
2. integration
3. analysis
4. actions, decisions

Fast Data, Big Analytics, Focuses Services

January 2015, 1,876 companies

**Needs:**
Real-Time, scalable, high-performance.

**Hadoop:** Compute and storage
Apache Hadoop project:
Enables distributed processing oflarge data across clusters of servers.
1. Low-cost
2. Scalabale (adding servers to cluser, etc.)
3. Fault-tolerant
4. Flexible (structured and unstructured data)
apache.org

##Basic Hadoop components
Data and processing together.
HDFS & Hadoop MapReduce
Data & Processing

**Map Step:** master orocess that divides problem into smaller sub-tasks ans distributes
**Reduce Step:** processed data from slave node and performs reduce tasks to form the final output
YARN MapReduce(Hadoop 2.0) -> has replaced MapReduce. submit jobs, reduce from multiple nodes, more flexible and fits into complex jobs.

##Big data projects
Succesfull data projects **basic rules:**
1. Dont start without understanding the value (know the ROI)
        1.1 start with the business question/problem
        1.2 dont start without understanding the value
2. Dont ignore the wider enterprise story
        1.1 integrate data that comes across the organization, differnet departments, different teams in the organization.
3. Not just a technology project! It is about business change, insight and value.















